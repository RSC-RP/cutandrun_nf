//working directory for temporary/intermediate files produced in the workflow processes
workDir = "$HOME/temp" 

//global parameters
params {
    // general options
    sample_sheet                = "./test_data/test_dataset_sample_sheet.csv"
    queue                       = 'sceaq'
    project                     = '207f23bf-acb6-4835-8bfe-142436acb58c'
    outdir                      = "./results/mouse"
    peaks_outdir                = "${params.outdir}/peak_calls"
    publish_dir_mode            = 'copy'

    //Bowtie params
    build_index                 = false
    fasta                       = '/gpfs/shared_data/Bowtie2/mm39.fa' // required
    index                       = '/gpfs/shared_data/Bowtie2/mm39_index/' // bowtie2 index path is required unless `build_index = true`
    save_unaligned              = false

    //spike-in params
    build_spike_index           = false
    spike_fasta                 = '/gpfs/shared_data/Bowtie2/GCF_000005845.2_ASM584v2_genomic.fa' //required
    spike_index                 = '/gpfs/shared_data/Bowtie2/ecoli_index' // bowtie2 index path is required unless `build_spike_index = true`

    //Picard module specific parameters
    remove_dups                 = false

    //Effective genome size 
    gsize                       = 1.87e9 //default genome size from MACS2 

    //SEACR params
    threshold                   = 0 //any value > 0 will use threshold, even if IgG is available in sample sheet
    spike_norm                  = false
    chrom_sizes                 = '/gpfs/shared_data/Bowtie2/mm39.chrom.sizes'
    scale_factor_constant       = 10000 //scientific notation NOT allowed

    //MACS2 and khmer params
    run_macs2                   = true
    run_khmer                   = false
    kmer_size                   = 150 //kmer_size is the read-length

    //MultiQC
    multiqc_config              = './multiqc_config.yml'
    extra_multiqc_config        = ''
    multiqc_logo                = ''
}

// Computational resource allocation for the processes run in the workflow
process {
    publishDir = [
        path: { "${params.outdir}/${task.process.tokenize(':')[-1].toLowerCase()}" },
        mode: params.publish_dir_mode,
        saveAs: { filename -> filename.equals('versions.yml') ? null : filename },
        failOnError: true,
    ]
    errorStrategy = "retry"
    maxRetries = 2

    //Quality trimming process specific parameters
    withName: TRIMGALORE {
        cpus = 2
        memory = 16.GB
        ext.args = ''
    }

    //Bowtie2 aligner process specific parameters
    withName: BOWTIE2_ALIGN {
        cpus = { 2 * task.attempt }
        memory = { 32.GB * task.attempt }
        ext.prefix = { "${meta.id}.sort" }
        ext.args = '--local --very-sensitive-local --no-unal --no-mixed --no-discordant --phred33 -I 10 -X 700'
        ext.args2 = ''      //command line arguments for `samtools sort`
    }

    /*
    //Optional filtering of aligned reads aligner process specific parameters
    withName: *:samtools_filter:SAMTOOLS_VIEW {
        cpus = { 1 * task.attempt }
        memory = { 16.GB * task.attempt }
        ext.prefix = { "${meta.id}.filter" }
        ext.args = '-q 30'
    }
    */

    //SEACR peak calling resources
    withName: SEACR_CALLPEAK {
        cpus = { 1 * task.attempt }
        memory = { 16.GB * task.attempt }
        ext.args = 'norm stringent'
        publishDir = [  path: { "${params.peaks_outdir}/${task.process.tokenize(':')[-1].toLowerCase()}" },
                        mode: params.publish_dir_mode,
                        saveAs: { filename -> filename.equals('versions.yml') ? null : filename },
                        failOnError: true,
                    ]
    }

    //MACS2 peak calling resources
    withName: MACS2_CALLPEAK {
        cpus = { 1 * task.attempt }
        memory = { 16.GB * task.attempt }
        ext.args = '-q 0.1 --keep-dup all'
        publishDir = [  path: { "${params.peaks_outdir}/${task.process.tokenize(':')[-1].toLowerCase()}" },
                        mode: params.publish_dir_mode,
                        saveAs: { filename -> filename.equals('versions.yml') ? null : filename },
                        failOnError: true,
                    ]
    }

    //BAMCOVERAGE bigwig file  parameters 
    withName: DEEPTOOLS_BAMCOVERAGE {
        cpus = { 4 * task.attempt }
        memory = { 16.GB * task.attempt }
        ext.args = '--normalizeUsing CPM --centerReads --verbose'
    }

    //Picard to Remove duplicate reads
    withName: PICARD_MARKDUPLICATES {
        cpus = { 2 * task.attempt }
        memory = { 32.GB * task.attempt }
        ext.prefix = { "${meta.id}.markedDup" }
        ext.args = '--CREATE_MD5_FILE true --CREATE_INDEX true'
    }

    //Picard to Remove duplicate reads
    withName: PICARD_RMDUPLICATES {
        cpus = { 2 * task.attempt }
        memory = { 32.GB * task.attempt }
        ext.prefix = { "${meta.id}.rmDup" }
        ext.args = '--REMOVE_DUPLICATES true --CREATE_MD5_FILE true --CREATE_INDEX true'
    }

    //Samtools sort by read name parameters
    withName: SAMTOOLS_NSORT {
        cpus = { 1 * task.attempt }
        memory = { 32.GB * task.attempt }
        ext.prefix = { "${meta.id}.nsort" }
        ext.args = '-n'
    }

    //convert bamtobed to bedgraph process specific resources
    withName: BAMTOBEDGRAPH {
        cpus = { 1 * task.attempt }
        memory = { 8.GB * task.attempt }
        ext.args = '' //for bedtools bamtobed
        ext.args2 = '' //for bedtools genomecov 
    }

    //Samtools sort by coordinate (for bedtools process below)
    withName: SAMTOOLS_SORT {
        cpus = { 1 * task.attempt }
        memory = { 32.GB * task.attempt }
        ext.prefix = { "${meta.id}.sort" }
        ext.args = ''
    }

    //Samtools sort by coordinate (for bedtools process below)
    withName: SAMTOOLS_INDEX {
        cpus = { 1 * task.attempt }
        memory = { 16.GB * task.attempt }
        ext.args = ''
    }

    withName: SAMTOOLS_STATS {
        cpus = { 1 * task.attempt }
        memory = { 16.GB * task.attempt }
        ext.args = ''
    }

    if ( params.build_index ){
        //Bowtie2 aligner process specific parameters
        withName: BOWTIE2_BUILD {
            cpus = { 4 * task.attempt }
            memory = { 32.GB * task.attempt }
            ext.args = '--verbose'
        }
    }

    withName: SAMTOOLS_FAIDX {
        cpus = { 1 * task.attempt }
        memory = { 16.GB * task.attempt }
        ext.args = ''
    }

    //FASTQC process specific parameters
    withName: FASTQC {
        cpus = 1
        memory = 16.GB
        ext.args = ''
    }

    //FASTQC_TRIM process specific parameters
    withName: FASTQC_TRIM {
        cpus = 1
        memory = 16.GB
        ext.args = ''
    }

    //MultiQC process specific parameters
    withName: MULTIQC {
        cpus = { 1 * task.attempt }
        memory = { 16.GB * task.attempt }
        ext.args = '--verbose'
    }

}

//Create profiles to easily switch between the different process executors and platforms.
params.enable_conda = false //set-to false except inside the PBS_conda profile
profiles {
    //For running on an interactive session on cybertron with singularity module loaded
    local_singularity {
        process.executor = 'local'
        singularity.enabled = true
    }
    //For executing the jobs on the HPC cluster with singularity containers
    PBS_singularity {
        process.executor = 'pbspro' 
        process.queue = "${params.queue}"
        process.clusterOptions = "-P ${params.project}"
        process.beforeScript = 'module load singularity'
        singularity.enabled = true
    }
    //For executing the jobs on the HPC cluster with conda environments. 
    PBS_conda {
        process.executor = 'pbspro' 
        process.queue = "${params.queue}"
        process.clusterOptions = "-P ${params.project}"
        params.enable_conda = true
    }
    //For running interactively on local macbook with docker installed. 
    local_docker {
        process.executor = 'local'
        docker.enabled = true
    }
}

//Configs for singularity containers on cybertron
singularity {
    autoMounts = true
    cacheDir = "$HOME/singularity"
    runOptions = '--containall --no-home'
}

//Use personal conda environments on cybertron if conda_enabled = true
conda {
    cacheDir = "$HOME/miniconda3/envs/"
}

//Configs for docker containers on local macbook with 64Gb memory
//docker.runOptions = '-u $(id -u):$(id -g)'
docker {
    temp = 'auto'
    runOptions = "--platform linux/amd64 --memory=32g --cpus=0.000"
}

//overwrite reports when the workflow is executed again 
report {
    overwrite = true
}
dag {
    overwrite = true
}